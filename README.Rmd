---
title: "eurodata -- R package for fast and easy Eurostata data import and search"
author: "Aleksander Rutkowski"
output:
html_document:
keep_md: true
---

```{r helpers, include=FALSE}
options(width = 120)
eurostat::clean_eurostat_cache() # in case repeated evaluation
cran <- function(package)
    paste0('https://cran.r-project.org/web/packages/',
           package,'/index.html')
rdoc <- function(package,funct)
    paste0('http://www.rdocumentation.org/packages/',
           package,'/functions/',funct)
lnk_ <- function(name,url)
    paste0('[',name,']','(',url,')')
lnk <- function(package,funct)
    paste0(lnk_(package,cran(package)),'::',
           lnk_(funct,rdoc(package,funct)))
estat_toc_link <-
    'http://ec.europa.eu/eurostat/estat-navtree-portlet-prod/BulkDownloadListing?file=table_of_contents_en.txt'
```

The package relies on [Eurostat's Bulk Download Facility](http://ec.europa.eu/eurostat/data/bulkdownload).

The core API contains just 6 functions -- 4 for data or metadata imports and 2 for search:

Import functionality:

- **importData** -- fast thanks to `r lnk('data.table','fread')`
- **importDataLabels** -- as above
- **importMetabase** -- as above
- **importDataList** -- reflects the hierarchical structure of the Eurostat tree of datasets --
fast transformation of the raw [Table of Contents file](`r estat_toc_link`)
is based on a C++ code snippet compiled via [Rcpp](`r cran('Rcpp')`)

Search functionality:

- **browseDataList** -- based on importDataList, shows an HTML table
(generated with `r lnk('xtable','xtable')`) in a browser with a list of the found datasets
- **find** -- based on importDataList, shows a textual report on the found datasets --
a ``quick-n-dirty'' way to find a Eurostat dataset without much typing (with a keyword or a few keywords)

## Installation

```{r installation, eval=FALSE, include=TRUE}
devtools::install_github('alekrutkowski/eurodata') # package 'devtools' needs to be installed
```

## Functionality demo

```{r attach_library}
library(eurodata)
```

### Imports

```{r import_demo, warning=FALSE, , message=FALSE}
x <- importData('nama_10_a10')  # actual dataset
str(x)
head(x,10)
# Friendly error if a wrong data code (similarly for importLabels):
tryCatch(importData('nama_10_a10_XXX'),
         error = function(e) cat(geterrmessage()))
y <- importDataList()  # metadata
colnames(y)
str(y[y$Code=='nama_10_a10',])  # metadata on x
z <- importLabels('geo')
head(z,10)
```

### Search

```{r background_setup, include=FALSE}
# A trick to display the side-effects:
library(magrittr)
cleanForGH <- function(x) x %>%
    substr(457, nchar(.)) %>%  # drop html style preamble not supported by GitHub md parser
    paste('<html>',.) %>%
    cat(sep='\n')
browseDataList <- function(...) eurodata::browseDataList(...)$html %>%
    cleanForGH
print.EurostatDataList <- function(x, SearchCriteria, ...) x %>%
    eurodata:::tableToHtml(Sys.time(), SearchCriteria) %>%
    list(html=.) %>%
    eurodata:::print.BrowsedEurostatDatasetList() %>%
    cleanForGH
find <- function(...) eurodata::find(...)$report %>%
    cat(sep='\n')
```

```{r find_demo}
# Free-style text search based on the parts of words in the dataset names
find(gdp,main,selected,-quarterly)
# Search based on the parts of the dataset codes
find(bop, its)
find(bop,-ybk,its)
```

```{r browse_demo, results='asis'}
browseDataList(grepl('GDP',`Dataset name`) &
                   grepl('main',`Dataset name`) &
                   grepl('selected',`Dataset name`) &
                   !grepl('quarterly',`Dataset name`))
browseDataList(grepl('bop',Code) & grepl('its',Code))
```

```{r}
# Producing a table of datasets which (1) include a dimension `sizeclas`
# (i.e. firm size class) and (2) some data for firms with fewer than 10 employees
# (`sizeclas` code "LT10") and (3) have sectorial data (i.e. include a
# dimension `nace_r2`).
library(magrittr)
metab <- importMetabase()
codes_with_nace <- metab %>% 
    subset(Dim_name=='nace_r2') %>%
    extract2('Code') %>%
    unique
final_codes <- metab %>%
    subset(Dim_name=='sizeclas' & Dim_val=='LT10' &
               Code %in% codes_with_nace) %>%
    extract2('Code') %>%
    unique
```

```{r, results='asis'}
importDataList() %>%
    subset(Code %in% final_codes) %>%
    as.EurostatDataList %>%
    # the `SearchCriteria` argument below is optional
    print(SearchCriteria =
              'those including data on firms with fewer than 10 employees and NACE Rev.2 disaggregation') 
```

## Speed demo

eurodata::**importData** compared to `r lnk('eurostat','get_eurostat')`:

```{r speed_demo, cache=TRUE}
y <- importDataList()  # metadata

d <- unique(y[y$Type=='dataset','Code']) # dataset codes

set.seed(1234)  # for replicability

d50 <- sample(d, 50) # a random sample of 50 datasets

get_eurostat <- eurostat::get_eurostat  # package 'eurostat' needs to be installed

FUNS <- c('importData', 'get_eurostat')

timeit <- function(funname, code)
    tryCatch(system.time(get(funname)(code))['elapsed'],
             error = function(e) as.numeric(NA)) # due to errors in some 'eurostat' package imports

compileInfo <-
    function(code) {
        FUNS2 <- if (sample(c(TRUE,FALSE), 1))
            FUNS else rev(FUNS) # so that the execution order is random
        res <- data.frame(code,
                          timeit(FUNS2[1], code),
                          timeit(FUNS2[2], code))
        colnames(res) <- c('Data code name',FUNS2)
        res
    }
```

```{r, message=FALSE, warning=FALSE, results='hide', cache=TRUE}
L <- lapply(d50, compileInfo) 
```

```{r, cache=TRUE}
Res <- do.call(rbind, L)

Res2 <- within(Res,
               ratio <- get_eurostat/importData)

row.names(Res2) <- NULL # to eliminate the visual noise

Res2 # lower = faster (in seconds)
# How many times eurodata::importData is faster on average?

mean(Res2$ratio, na.rm=TRUE)
median(Res2$ratio, na.rm=TRUE)
```
